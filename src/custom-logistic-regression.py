
# coding: utf-8

# In[1]:




# In[2]:

#!/usr/bin/env python


import sys
import numpy
numpy.seterr(all='ignore')
 
def sigmoid(x):
    return 1. / (1 + numpy.exp(-x))

def softmax(x):
    e = numpy.exp(x - numpy.max(x))  # prevent overflow
    if e.ndim == 1:
        return e / numpy.sum(e, axis=0)
    else:  
        return e / numpy.array([numpy.sum(e, axis=1)]).T  # ndim = 4


class LogisticRegression(object):
    def __init__(self, input, label, n_in, n_out):
        self.x = input
        self.y = label
        self.W = numpy.zeros((n_in, n_out))  # initialize W 0
        self.b = numpy.zeros(n_out)          # initialize bias 0

        # self.params = [self.W, self.b]

    def train(self, lr=0.1, input=None, L2_reg=0.00):
        if input is not None:
            self.x = input

        # p_y_given_x = sigmoid(numpy.dot(self.x, self.W) + self.b)
        p_y_given_x = softmax(numpy.dot(self.x, self.W) + self.b)
        d_y = self.y - p_y_given_x
        
        self.W += lr * numpy.dot(self.x.T, d_y) - lr * L2_reg * self.W
        self.b += lr * numpy.mean(d_y, axis=0)
        
        # cost = self.negative_log_likelihood()
        # return cost

    def negative_log_likelihood(self):
        # sigmoid_activation = sigmoid(numpy.dot(self.x, self.W) + self.b)
        sigmoid_activation = softmax(numpy.dot(self.x, self.W) + self.b)

        cross_entropy = - numpy.mean(
            numpy.sum(self.y * numpy.log(sigmoid_activation) +
            (1 - self.y) * numpy.log(1 - sigmoid_activation),
                      axis=1))

        return cross_entropy


    def predict(self, x):
        # return sigmoid(numpy.dot(x, self.W) + self.b)
        return softmax(numpy.dot(x, self.W) + self.b)


def test_lr(learning_rate=0.01, n_epochs=200):
    # training data
    x = numpy.array([[3,5,1.6,0.2],
                    [3.2,4.7,1.6,0.2],
                    [3.4,4.6,1.4,0.3],
                    [3.6,5,1.4,0.2],
                    [4.1,5.2,1.5,0.1],
                    [3,4.9,1.4,0.2],
                    [3.3,5.1,1.7,0.5],
                    [3.4,4.8,1.6,0.2],
                    [3.7,5.1,1.5,0.4],
                    [3.1,4.9,1.5,0.1],
                    [3.6,4.6,1,0.2],
                    [3.9,5.4,1.7,0.4],
                    [3,4.3,1.1,0.1],
                    [2.9,4.4,1.4,0.2],
                    [3.4,5,1.5,0.2],
                    [3.5,5.1,1.4,0.2],
                    [3.2,5,1.2,0.2],
                    [3.8,5.1,1.9,0.4],
                    [3,4.8,1.4,0.3],
                    [4.2,5.5,1.4,0.2],
                    [3.7,5.4,1.5,0.2],
                    [3,4.8,1.4,0.1],
                    [3.3,5,1.4,0.2],
                    [3.2,4.7,1.3,0.2],
                    [3.5,5.1,1.4,0.3],
                    [3.4,4.8,1.9,0.2],
                    [3.4,5.4,1.5,0.4],
                    [3.8,5.1,1.5,0.3],
                    [3,4.4,1.3,0.2],
                    [3.5,5,1.3,0.3],
                    [3.5,5,1.6,0.6],
                    [3.9,5.4,1.3,0.4],
                    [3.1,4.6,1.5,0.2],
                    [3.8,5.7,1.7,0.3],
                    [4,5.8,1.2,0.2],
                    [3.7,5.3,1.5,0.2],
                    [3.4,5,1.6,0.4],
                    [3.2,4.4,1.3,0.2],
                    [3.4,5.4,1.7,0.2],
                    [3.2,4.6,1.4,0.2],
                    [3.5,5.5,1.3,0.2],
                    [3.1,4.8,1.6,0.2],
                    [3.1,4.9,1.5,0.1],
                    [3.4,5.2,1.4,0.2],
                    [2.3,4.5,1.3,0.3],
                    [2.8,6.4,5.6,2.1],
                    [3.2,6.4,5.3,2.3],
                    [2.8,6.2,4.8,1.8],
                    [2.5,6.3,5,1.9],
                    [3,6.1,4.9,1.8],
                    [3.3,6.3,6,2.5],
                    [2.6,7.7,6.9,2.3],
                    [2.7,6.3,4.9,1.8],
                    [2.5,4.9,4.5,1.7],
                    [3,5.9,5.1,1.8],
                    [3.1,6.4,5.5,1.8],
                    [3.8,7.7,6.7,2.2],
                    [3.4,6.2,5.4,2.3],
                    [3.2,6.8,5.9,2.3],
                    [3.1,6.9,5.1,2.3],
                    [3,6.8,5.5,2.1],
                    [3.3,6.7,5.7,2.5],
                    [3.2,6.9,5.7,2.3],
                    [3,7.6,6.6,2.1],
                    [2.8,6.4,5.6,2.2],
                    [2.2,6,5,1.5],
                    [2.9,7.3,6.3,1.8],
                    [3,7.1,5.9,2.1],
                    [3,7.2,5.8,1.6],
                    [3,6,4.8,1.8],
                    [2.8,5.6,4.9,2],
                    [2.9,6.3,5.6,1.8],
                    [2.7,5.8,5.1,1.9],
                    [2.7,5.8,5.1,1.9],
                    [2.5,6.7,5.8,1.8],
                    [2.8,6.3,5.1,1.5],
                    [3.3,6.7,5.7,2.1],
                    [3.2,7.2,6,1.8],
                    [2.5,5.7,5,2],
                    [3.4,6.3,5.6,2.4],
                    [3.1,6.9,5.4,2.1],
                    [3,6.5,5.2,2],
                    [3,7.7,6.1,2.3],
                    [2.8,7.4,6.1,1.9],
                    [2.8,7.7,6.7,2],
                    [3.6,7.2,6.1,2.5],
                    [2.6,6.1,5.6,1.4],
                    [3,6.7,5.2,2.3],
                    [3,6.5,5.8,2.2],
                    [2.7,6.4,5.3,1.9],
                    [2.7,5.6,4.2,1.3],
                    [3,5.9,4.2,1.5],
                    [3,6.1,4.6,1.4],
                    [2.3,5.5,4,1.3],
                    [2.8,5.7,4.1,1.3],
                    [3,5.6,4.5,1.5],
                    [2.8,6.8,4.8,1.4],
                    [3.1,6.7,4.4,1.4],
                    [2.5,5.5,4,1.3],
                    [2.9,6.2,4.3,1.3],
                    [3.1,6.9,4.9,1.5],
                    [2.4,5.5,3.8,1.1],
                    [2.8,6.1,4.7,1.2],
                    [3,6.7,5,1.7],
                    [2.8,6.1,4,1.3],
                    [2.9,6.4,4.3,1.3],
                    [2.7,6,5.1,1.6],
                    [2.7,5.8,4.1,1],
                    [2.6,5.8,4,1.2],
                    [3,5.7,4.2,1.2],
                    [2.4,5.5,3.7,1],
                    [2.5,5.1,3,1.1],
                    [3.4,6,4.5,1.6],
                    [2.3,5,3.3,1],
                    [2.9,5.7,4.2,1.3],
                    [2.7,5.8,3.9,1.2],
                    [2.6,5.5,4.4,1.2],
                    [2,5,3.5,1],
                    [2.5,5.6,3.9,1.1],
                    [3,5.4,4.5,1.5],
                    [2.3,6.3,4.4,1.3],
                    [2.8,6.5,4.6,1.5],
                    [3,6.6,4.4,1.4],
                    [2.9,6,4.5,1.5],
                    [2.7,5.2,3.9,1.4],
                    [2.5,6.3,4.9,1.5],
                    [3.2,6.4,4.5,1.5],
                    [2.9,6.1,4.7,1.4],
                    [2.9,5.6,3.6,1.3],
                    [2.2,6,4,1],
                    [3.3,6.3,4.7,1.6],
                    [3.1,6.7,4.7,1.5],
                    [2.9,6.6,4.6,1.3],
                    [3,5.6,4.1,1.3],
                    [3.2,5.9,4.8,1.8]])
    y = numpy.array([[1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [1,0,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,1,0],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1],
                    [0,0,1]])


    # construct LogisticRegression
    classifier = LogisticRegression(input=x, label=y, n_in=4, n_out=3)

    # train
    for epoch in range(n_epochs):
        classifier.train(lr=learning_rate)
        cost = classifier.negative_log_likelihood()
        print(sys.stderr, 'Training epoch %d, cost is ' % epoch, cost)
        learning_rate *= 0.95


    # test
    x = numpy.array([3,5,1.6,0.2])
    print(sys.stderr, classifier.predict(x))


if __name__ == "__main__":
    test_lr()


# In[ ]:





# In[ ]:



